{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T11:18:05.233145Z",
     "start_time": "2020-05-30T11:18:05.168563Z"
    }
   },
   "outputs": [],
   "source": [
    "import amlutils\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:36:52.531851Z",
     "start_time": "2020-05-30T10:36:52.520943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:36:54.220405Z",
     "start_time": "2020-05-30T10:36:52.533805Z"
    }
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:18.307425Z",
     "start_time": "2020-05-30T10:37:16.957961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country_code', 'date_added', 'job_board', 'job_description', 'job_title', 'job_type', 'location', 'organization', 'page_url', 'phone_number', 'salary', 'sector']\n",
      "21919\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"./data/Dice_US_jobs.csv\"\n",
    "csv_data = amlutils.csv_utils.parse_csv_file(csv_file, quotechar='\"', encoding=\"latin-1\")\n",
    "headers = csv_data[0]\n",
    "csv_data = csv_data[1:]\n",
    "START_TOKEN = \"<start_token>\"\n",
    "END_TOKEN = \"<end_token>\"\n",
    "\n",
    "print(headers)\n",
    "print(len(csv_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:18.319364Z",
     "start_time": "2020-05-30T10:37:18.309359Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def striphtml(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', data)\n",
    "\n",
    "def stripnewlinechars(data):\n",
    "    data = data.replace(r\"\\n\", \"\")\n",
    "    data = data.replace(r\"\\r\", \"\")\n",
    "    return data\n",
    "\n",
    "def add_start_and_end_token(string, start_token=START_TOKEN, end_token=END_TOKEN):\n",
    "    return \"{} {} {}\".format(start_token, string, end_token) \n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    s = striphtml(sentence)\n",
    "    return add_start_and_end_token(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:19.119279Z",
     "start_time": "2020-05-30T10:37:18.321572Z"
    }
   },
   "outputs": [],
   "source": [
    "job_description_index = headers.index(\"job_description\")\n",
    "job_title_index = headers.index(\"job_title\")\n",
    "job_titles = [row[job_title_index] for row in csv_data]\n",
    "job_descriptions = [row[job_description_index] for row in csv_data]\n",
    "\n",
    "start_end_token_descriptions = [preprocess_sentence(desc) for desc in job_descriptions]\n",
    "start_end_token_job_titles = [preprocess_sentence(title) for title in job_titles]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:19.375194Z",
     "start_time": "2020-05-30T10:37:19.370619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_token> minimum required skills:edi, trustedlink, as2, vanif you are an edi analyst with experience, please read on!we are a strong, long standing company looking for an edi analyst for our team.  you must have 3+ years of edi experience  in a trustedlink for i environment. your role will work with our finance department identifying trading partners, work closely with external customers and be the edi liaison across the company. you will also monitor as2 and van communications, correct errors and incoming data.what you need for this positionrequirements:3+ years of edi experience3+ years of trustedlink for i experience, iseries/as400experience with van and as2 communicationswhat's in it for youwe offer a strong compensation package and benefits!local candidates only please.so, if you are an edi analyst with experience, please apply today!applicants must be authorized to work in the u.s.please apply directly to by clicking 'click here to apply' with your word resume!looking forward to receiving your resume and going over the position in more detail with you.- not a fit for this position? click the link at the bottom of this email to search all of our open positions.looking forward to receiving your resume!cybercoderscybercoders, inc is proud to be an equal opportunity employerall qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.your right to work - in compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the united states and to complete the required employment eligibility verification document form upon hire.copyright å© 1999 - 2016 . cybercoders, inc. all rights reserved. <end_token> <start_token> edi analyst <end_token>\n"
     ]
    }
   ],
   "source": [
    "print(start_end_token_descriptions[0], start_end_token_job_titles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:19.819254Z",
     "start_time": "2020-05-30T10:37:19.814342Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(data, maxlen=None):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='#$%&()*+,-./:;=?@[\\\\]^`{|}~\\t\\n')\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    data_sequences = tokenizer.texts_to_sequences(data)\n",
    "    padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        data_sequences,\n",
    "        maxlen=maxlen,\n",
    "        padding=\"post\",\n",
    "    )\n",
    "    return padded_sequences, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:48.413045Z",
     "start_time": "2020-05-30T10:37:20.470851Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sequences, train_tokenizer = tokenize(start_end_token_descriptions, maxlen=4000)\n",
    "label_sequences, label_tokenizer = tokenize(start_end_token_job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:48.422795Z",
     "start_time": "2020-05-30T10:37:48.416034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 4000\n"
     ]
    }
   ],
   "source": [
    "max_length_targ, max_length_inp = label_sequences.shape[1], train_sequences.shape[1]\n",
    "print(max_length_targ, max_length_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:53.589681Z",
     "start_time": "2020-05-30T10:37:48.425318Z"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_sequences)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(train_sequences) // BATCH_SIZE\n",
    "embedding_dim = 128\n",
    "units = 256\n",
    "vocab_inp_size = len(train_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(label_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_sequences, label_sequences)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:54.274183Z",
     "start_time": "2020-05-30T10:37:53.593668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 4000]), TensorShape([64, 18]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:54.290075Z",
     "start_time": "2020-05-30T10:37:54.276117Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.enc_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer='glorot_uniform',\n",
    "        )\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:54.308030Z",
     "start_time": "2020-05-30T10:37:54.292070Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:58.062728Z",
     "start_time": "2020-05-30T10:37:54.310023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 4000, 256)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 256)\n"
     ]
    }
   ],
   "source": [
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:58.074662Z",
     "start_time": "2020-05-30T10:37:58.065686Z"
    }
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:58.979359Z",
     "start_time": "2020-05-30T10:37:58.076938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 256)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 4000, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:58.992288Z",
     "start_time": "2020-05-30T10:37:58.981347Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:59.131951Z",
     "start_time": "2020-05-30T10:37:58.994282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4093)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(\n",
    "    tf.random.uniform((BATCH_SIZE, 1)),\n",
    "    sample_hidden, sample_output,\n",
    ")\n",
    "\n",
    "print(\"Decoder output shape: (batch_size, vocab size) {}\".format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:59.141890Z",
     "start_time": "2020-05-30T10:37:59.133911Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:59.151860Z",
     "start_time": "2020-05-30T10:37:59.143883Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./models/dice_model/\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:37:59.169851Z",
     "start_time": "2020-05-30T10:37:59.153856Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([label_tokenizer.word_index[START_TOKEN]] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T07:31:01.527442Z",
     "start_time": "2020-05-29T07:31:01.517441Z"
    }
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-29T07:30:21.148Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(\"Epoch {} Batch {} Loss {:.4f}\".format(\n",
    "                epoch + 1,\n",
    "                batch,\n",
    "                batch_loss.numpy()),\n",
    "            )\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print(\"Epoch {} Loss {:.4f}\".format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print(\"Time taken for 1 epoch {} sec\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:38:20.458992Z",
     "start_time": "2020-05-30T10:38:19.463554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1af359cbf48>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:38:23.124215Z",
     "start_time": "2020-05-30T10:38:23.112247Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_job_title(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    words = [word for word in sentence.split(\" \") if word in train_tokenizer.word_index]\n",
    "    inputs = [train_tokenizer.word_index[i] for i in words]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [inputs],\n",
    "        maxlen=max_length_inp,\n",
    "        padding=\"post\",\n",
    "    )\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = \"\"\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([label_tokenizer.word_index[START_TOKEN]], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += label_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if label_tokenizer.index_word[predicted_id] == END_TOKEN:\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T10:59:27.583779Z",
     "start_time": "2020-05-30T10:59:27.577796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start_token> minimum required skills:civil engineering, autocad, site layout, conceptual designthis role will require an expertise in site layout and grading for commercial builds. candidates with experience working on federal projects is a huge plus!our contractor is a full service contractor, providing; architectural and engineering design; environmental consulting; remediation; and operations and maintenance services to municipal, government, and private sector clients throughout new england and adjacent states.what you will be doingthe civil engineer will be responsible for maintaining client relationships through the successful management of projects and/or leading design efforts on a project. the civil engineer will conduct a wide variety of engineering tasks including conceptual designs, engineering reports/studies, detailed designs including drawings and specifications, and cost estimates.- engineering of site layout, grading, drainage- use autocad for engineering design- prepare/support proposals to support base line engineering workload.- coordinate execution of engineering field work on specific projects.- coordinate the preparation of project design submittals for permitting, bidding, and/or construction. responsible for being a civil designer of record.- coordinate construction inspection services and/or construction phase services, as required. responsible for conducting the construction inspection services and/or construction phase services for the civil engineering disciplinwhat you need for this positionb.s. degree in civil engineering required.professional registration in at least one new england state, preferably massachusetts.proficiency in autocad required.a minimum of 5 years of experience.   - civil engineering   - autocad   - site layout   - conceptual design   - estimatingwhat's in it for youwe offer excellent compensation packages and benefits, including medical, dental, and vision insurance, and an attractive 401(k) plan.so, if you are a civil engineer, p.e. with experience, please apply today!applicants must be authorized to work in the u.s.please apply directly to by clicking 'click here to apply' with your word resume!looking forward to receiving your resume and going over the position in more detail with you.- not a fit for this position? click the link at the bottom of this email to search all of our open positions.looking forward to receiving your resume!cybercoderscybercoders, inc is proud to be an equal opportunity employerall qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.your right to work - in compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the united states and to complete the required employment eligibility verification document form upon hire.copyright å© 1999 - 2016 . cybercoders, inc. all rights reserved. <end_token>\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_desc = \"Minimum Required Skills:Civil Engineering, AutoCAD, Site Layout, Conceptual DesignThis role will require an expertise in Site Layout and Grading for Commercial Builds. Candidates with experience working on federal projects is a huge plus!Our contractor is a full service contractor, providing; architectural and engineering design; environmental consulting; remediation; and operations and maintenance services to municipal, government, and private sector Clients throughout New England and adjacent states.What You Will Be DoingThe Civil Engineer will be responsible for maintaining client relationships through the successful management of projects and/or leading design efforts on a project. The Civil Engineer will conduct a wide variety of engineering tasks including conceptual designs, engineering reports/studies, detailed designs including drawings and specifications, and cost estimates.- Engineering of site layout, grading, drainage- Use AutoCAD for Engineering Design- Prepare/support proposals to support base line engineering workload.- Coordinate execution of engineering field work on specific projects.- Coordinate the preparation of project design submittals for permitting, bidding, and/or construction. Responsible for being a Civil Designer of Record.- Coordinate construction inspection services and/or construction phase services, as required. Responsible for conducting the construction inspection services and/or construction phase services for the civil engineering disciplinWhat You Need for this PositionB.S. Degree in Civil Engineering required.Professional Registration in at least one New England state, preferably Massachusetts.Proficiency in AutoCAD required.A minimum of 5 years of experience.   - Civil Engineering   - AutoCAD   - Site Layout   - Conceptual Design   - EstimatingWhat's In It for YouWe offer excellent compensation packages and benefits, including medical, dental, and vision insurance, and an attractive 401(k) plan.So, if you are a Civil Engineer, P.E. with experience, please apply today!Applicants must be authorized to work in the U.S.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!Looking forward to receiving your resume and going over the position in more detail with you.- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.Looking forward to receiving your resume!CyberCodersCyberCoders, Inc is proud to be an Equal Opportunity EmployerAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.Copyright å© 1999 - 2016 . CyberCoders, Inc. All rights reserved.\"\n",
    "preprocess_sentence(job_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T11:59:03.571367Z",
     "start_time": "2020-05-30T11:18:10.089051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338f23207e374bbdacd05a8c5bc63e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21919.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "job_titles_predicted = []\n",
    "for job_desc in tqdm(job_descriptions):\n",
    "    jt = get_job_title(job_desc.replace(\"\\r\", \" \").replace(\"\\n\", \" \"))\n",
    "    job_titles_predicted.append(jt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T13:28:59.219469Z",
     "start_time": "2020-05-31T13:28:59.213481Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_bleu_n_gram(groundtruths, prediction, n=1):\n",
    "    groundtruth_list = [gs.split(\" \") for gs in groundtruths]\n",
    "    prediction_list = prediction.split(\" \")\n",
    "    return compute_bleu_score(groundtruth_list, prediction_list, np.eye(n)[n-1])\n",
    "    \n",
    "def compute_bleu_score(groundtruth_list, prediction_list, weights):\n",
    "    return nltk.translate.bleu_score.sentence_bleu(\n",
    "        groundtruth_list,\n",
    "        prediction_list,\n",
    "        weights=weights,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T13:33:59.989338Z",
     "start_time": "2020-05-31T13:33:57.955573Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for i, jt_predicted in enumerate(job_titles_predicted):\n",
    "    prediction = jt_predicted.replace(\"<end_token>\", \"\").replace(\"<start_token>\", \"\").strip().lower()\n",
    "    bl_1 = compute_bleu_n_gram([job_titles[i].strip().lower()], prediction, n=1)\n",
    "    bl_2 = compute_bleu_n_gram([job_titles[i].strip().lower()], prediction, n=2)\n",
    "    metrics.append((bl_1, bl_2, 1 if job_titles[i].lower() == prediction.strip().lower() else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T13:33:43.418368Z",
     "start_time": "2020-05-31T13:33:43.403425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21919, 21919, 21919)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_1s, bleu_2s, matches = zip(*metrics)\n",
    "len(bleu_1s), len(bleu_2s), len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T13:33:43.436474Z",
     "start_time": "2020-05-31T13:33:43.423350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches 6660\n",
      "BLEU 1 0.5345026429116695\n",
      "BLEU 2 0.3973641292158458\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "print(f\"Exact matches {sum(matches)}\")\n",
    "print(f\"BLEU 1 {np.mean(bleu_1s)}\")\n",
    "print(f\"BLEU 2 {np.mean(bleu_2s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu-2.1.0]",
   "language": "python",
   "name": "conda-env-tf_gpu-2.1.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
